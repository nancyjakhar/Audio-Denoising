# Audio-Denoising
Audio Denoising using Spectral Gatting
Noise reduction in audio files is a crucial task in various fields such as audio processing, 
speech recognition, music production, and telecommunications. Unwanted noise in audio 
files can degrade the quality of audio recordings, distort speech or music signals, and affect 
the overall listening experience. Therefore, effective noise reduction techniques are 
essential for improving audio quality and enhancing the performance of audio-based 
applications. 
Numerous algorithms have been proposed for noise reduction in audio files, ranging from 
simple filtering methods to sophisticated statistical signal processing techniques. Common 
approaches include spectral subtraction, Wiener filtering, and adaptive filtering, among 
others. These algorithms aim to attenuate or remove noise from audio signals while 
preserving the desired audio content. 
In this project, we focused on improving the noise reduction algorithm using Spectral 
Gating and Fast Fourier Transform (FFT) implemented in Python modules. Spectral gating 
is a technique that involves estimating the noise spectrum from a noisy audio signal and 
then applying a gain function to suppress the noise in the spectral domain. 
# Dataset 
The dataset used for evaluating the performance of our algorithm consists of two parts: 
## Our Own Generated Audio Files: 
We created our own set of audio files for testing the algorithm. These files were 
generated using a custom script that simulated various environmental conditions, such 
as different levels of background noise, reverberation, and interference. The audio files 
were saved in WAV format with a sample rate of 44.1 kHz and 16-bit resolution. The 
characteristics of these audio files, such as the type of speech, duration, and signal 
characteristics, were controlled during the generation process to ensure consistency and 
reproducibility in our experiments. 
## Clean and Noisy Parallel Speech 𝑑𝑎𝑡𝑎𝑠𝑒𝑡
We also used an online published dataset for evaluating the performance of our 
algorithm. This dataset, provided by the University of Edinburgh, consists of pairs of 
clean speech signals and their corresponding noisy versions. The clean speech signals 
are recorded in a controlled environment, while the noisy versions are generated by 
adding various types and levels of noise to the clean speech signals. The dataset 
includes different types of speech, such as male and female voices, different languages, 
and various speaking styles. The audio files are in WAV format with a sample rate of 
44.1 kHz and 16-bit resolution.


